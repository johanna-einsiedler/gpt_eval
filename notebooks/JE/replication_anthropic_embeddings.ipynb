{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.cluster import KMeans\n",
    "from openai import OpenAI\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#OPENAI_API_KEY ="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Replicate procedure outline in Appendix B\n",
    "https://assets.anthropic.com/m/2e23255f1e84ca97/original/Economic_Tasks_AI_Paper.pdf\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Embed task names.\n",
    "Embeds tasks names using the all-mpnet-base-v2 [Reimers and Gurevych, 2022] sentence transformer to obtain 768-dimensional vector representations of each task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "onet_data = '../../data/external/onet_data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in ONET task data\n",
    "df = pd.read_csv(onet_data + 'start_sample_dwa_task_list.csv')\n",
    "\n",
    "# create a small dataset to just test hte workflow\n",
    "df = df.loc[0:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get task names\n",
    "task_names = df['Task']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-5.1114074e-04 -1.0107846e-02  1.5378774e-02 ... -2.3617710e-04\n",
      "   2.2474973e-02 -2.5179697e-02]\n",
      " [-2.6967600e-03  1.6098229e-02 -9.4099334e-03 ... -3.7298994e-03\n",
      "   2.5657978e-02 -1.7094379e-02]\n",
      " [ 2.0684568e-02  7.8259163e-02 -1.4048434e-02 ... -1.4728837e-02\n",
      "   3.5283066e-02 -3.2388285e-02]\n",
      " ...\n",
      " [ 6.9529973e-02  1.1266973e-01 -5.1428413e-04 ...  2.7145812e-02\n",
      "  -1.5411461e-03  6.5058313e-02]\n",
      " [-3.0856816e-02  6.5693356e-02 -1.9286772e-02 ... -3.8616525e-04\n",
      "  -5.3530548e-02 -2.3597579e-02]\n",
      " [ 5.1545338e-03  2.6121160e-02  3.1633841e-05 ... -1.0486379e-02\n",
      "  -1.7431175e-02 -7.3188781e-03]]\n"
     ]
    }
   ],
   "source": [
    "# load model and create embeddings\n",
    "model = SentenceTransformer('sentence-transformers/all-mpnet-base-v2')\n",
    "embeddings = model.encode(task_names)\n",
    "print(embeddings)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Generate neighborhoods.\n",
    "Group these embeddings into k neighborhoods using k-means clustering, where k is chosen so that the average number of tasks per neighborhood is 40.\n",
    "We group tasks into neighborhoods because the names and descriptions for all base clusters may not fit within Claude’s context window."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set parameters\n",
    "\n",
    "avg_num_tasks = 2\n",
    "k = int(df.shape[0]/avg_num_tasks)\n",
    "\n",
    "kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
    "clusters = kmeans.fit_predict(embeddings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([28, 14, 14,  4,  4, 14,  4,  4,  4, 28, 23, 23, 22,  8, 23,  8,  8,\n",
       "       23,  3,  3, 24,  3,  3, 37, 33,  9,  9,  0,  9, 18, 18, 38,  2,  2,\n",
       "       38, 38,  2, 39, 16, 16, 12, 12,  1,  1, 27, 27, 12, 12, 27, 31, 29,\n",
       "       11, 27, 20, 20, 30, 20,  5,  5,  5, 35,  6, 26, 32, 15, 15, 13, 34,\n",
       "       21, 10, 36, 10, 25, 15, 21,  2,  7,  2, 11, 19, 17], dtype=int32)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intermediate step: Generate name and description.\n",
    "\n",
    "Not mentioned in the latest paper but in the Clio paper on p. 39"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define number of tasks outside cluster to be considered\n",
    "# define m (not given in the paper?!)\n",
    "#m = int(avg_num_tasks*0.2)\n",
    "m =2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"\"\"You are tasked with summarizing a group of related statements into a short, precise,\n",
    "and accurate description and name. Your goal is to create a concise summary\n",
    "that captures the essence of these statements and distinguishes them from other\n",
    "similar groups of statements.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_prompt = f\"\"\"ArithmeticErrorSummarize all the statements into a clear, precise, two-sentence description in the\n",
    "past tense. Your summary should be specific to this group and distinguish it\n",
    "from the contrastive answers of the other groups.\n",
    "After creating the summary, generate a short name for the group of statements. This\n",
    "name should be at most ten words long (perhaps less) and be specific but also\n",
    "reflective of most of the statements (rather than reflecting only one or two).\n",
    "The name should distinguish this group from the contrastive examples. For\n",
    "instance, \"Write fantasy sexual roleplay with octopi and monsters\", \"Generate\n",
    "blog spam for gambling websites\", or \"Assist with high school math homework\"\n",
    "would be better and more actionable than general terms like \"Write erotic\n",
    "content\" or \"Help with homework\". Be as descriptive as possible and assume\n",
    "neither good nor bad faith. Do not hesitate to identify and describe socially\n",
    "harmful or sensitive topics specifically; specificity is necessary for\n",
    "monitoring.\n",
    "Present your output in the following format:\n",
    "<summary> [Insert your two-sentence summary here] </summary>\n",
    "<name> [Insert your generated short name here] </name>\n",
    "\n",
    "Below are the related statements:\n",
    "\n",
    "{tasks_cluster}\n",
    "\n",
    "For context, here are statements from nearby groups that are NOT part of the group\n",
    "you’re summarizing:\n",
    "\n",
    "{tasks_closest}\n",
    "Do not elaborate beyond what you say in the tags. Remember to analyze both the\n",
    "statements and the contrastive statements carefully to ensure your summary and\n",
    "name accurately represent the specific group while distinguishing it from\n",
    "others.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "assistant_prompt = \"\"\"Sure, I will provide a clear, precise, and accurate summary and name for\n",
    "this cluster. I will be descriptive and assume neither good nor bad faith. Here\n",
    "is the summary, which I will follow with the name:\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "client = OpenAI(\n",
    "    #api_key=os.environ.get(\"OPENAI_API_KEY\"),  # This is the default and can be omitted\n",
    "    api_key = OPENAI_API_KEY\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop throuch clusters\n",
    "cluster_descriptions = pd.DataFrame()\n",
    "for cluster in clusters:\n",
    "    # get tasks in this cluster\n",
    "    tasks_cluster = list(df['Task'][clusters==cluster])\n",
    "\n",
    "    # get cluster centroid\n",
    "    cluster_centroid = kmeans.cluster_centers_[cluster]\n",
    "\n",
    "    # get m closest tasks outside the clusters\n",
    "    embeddings_not_in_cluster = embeddings[clusters!=cluster]\n",
    "    distances = np.linalg.norm(embeddings_not_in_cluster - cluster_centroid, axis=1)\n",
    "    closest = distances.argsort()[:m]\n",
    "    tasks_closest = list(df['Task'][closest])\n",
    "\n",
    "    chat_completion = client.chat.completions.create(\n",
    "        messages=[\n",
    "            {\"role\": \"developer\", \"content\": system_prompt},\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": user_prompt\n",
    "            },\n",
    "            {\"role\": \"assistant\", \"content\":assistant_prompt},\n",
    "\n",
    "        ],\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        temperature = 1\n",
    "    )\n",
    "    answer = chat_completion.choices[0].message.content\n",
    "\n",
    "    cluster_descriptions = pd.concat([cluster_descriptions, pd.Series([cluster,answer])],axis=1)\n",
    "cluster_descriptions = cluster_descriptions.T\n",
    "cluster_descriptions = cluster_descriptions.rename(columns={0:'cluster', 1:'answer'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Regular expression patterns to match summary and name\n",
    "summary_pattern = r'<summary>\\s*(.*?)\\s*</summary>'\n",
    "name_pattern = r'<name>\\s*(.*?)\\s*</name>'\n",
    "\n",
    "# Function to extract summary and name\n",
    "def extract_summary_and_name(text):\n",
    "    summary_match = re.search(summary_pattern, text)\n",
    "    name_match = re.search(name_pattern, text)\n",
    "    \n",
    "    summary_text = summary_match.group(1) if summary_match else None\n",
    "    name_text = name_match.group(1) if name_match else None\n",
    "    \n",
    "    return pd.Series([summary_text, name_text])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_descriptions[['summary', 'name']] = cluster_descriptions['answer'].apply(extract_summary_and_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_descriptions.to_csv('../../data/interim/anthropic_replication/base_summary_name.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Propose new tasks for each neighborhood.\n",
    "For each neighborhood, use Claude to propose\n",
    "candidate higher-level task descriptions by examining both the tasks within the neighborhood and the nearest m tasks outside it. Including the nearest tasks beyond the neighborhood ensures that tasks (or groups of tasks) on the boundary between neighborhoods are neither\n",
    "overcounted nor undercounted. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hierarchy parameters\n",
    "# number of levels\n",
    "L = 3\n",
    "# number of observations no the base level\n",
    "n_base = df.shape[0]\n",
    "\n",
    "# number of observations at the top hierachy level\n",
    "n_top = 12\n",
    "\n",
    "# desired level ratio asdefined in the paper\n",
    "level_ratio = (n_top/n_base)**(1/(L-1)) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use ChatGPT to propose new task for each neighborhood."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clusters_df = pd.concat([df['Task'], pd.Series(clusters).rename('cluster_number')],axis = 1)\n",
    "# clusters_df['cluster'] = 'Cluster '+ clusters_df['cluster_number'].astype(str)\n",
    "# clusters_df = clusters_df.sort_values('cluster_number')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"\"\"You are tasked with creating higher-level cluster names based on a\n",
    "given list of clusters and their descriptions. Your goal is to come up\n",
    "with broader categories that could encompass one or more of the provided\n",
    "clusters.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "desired_names = level_ratio * n_base\n",
    "cluster_list = list(cluster_descriptions['name'].astype(str) + ': ' +cluster_descriptions['summary'].astype(str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_prompt = f\"\"\"First, review the list of clusters and their descriptions: \n",
    "{cluster_list} \n",
    "\n",
    "\n",
    "Your task is to create roughly {desired_names} higher-level cluster names\n",
    "that could potentially include one or more of the provided clusters.\n",
    "These higher-level clusters should represent broader categories or\n",
    "themes that emerge from the given clusters, while remaining as specific\n",
    "as possible. If there are many clusters with a specific theme, ensure\n",
    "that the higher-level cluster name remains the maximum level of\n",
    "specificity. You are helping to organize user behavior data in order to\n",
    "improve safety, monitoring, and observability. You can generate more or\n",
    "less than {desired_names} names if you feel that more or fewer are\n",
    "appropriate and accurately capture the clusters. You should output at\n",
    "least {int(0.5 * desired_names)} and at most {int(1.5 * desired_names)}\n",
    "names, with {desired_names} as a target.\n",
    "Guidelines for creating higher-level cluster names:\n",
    "1. Analyze the themes, topics, or characteristics common to multiple\n",
    "clusters.\n",
    "2. Create names that are specific enough to be meaningful, but not so\n",
    "specific that they can’t meaningfully represent many different clusters.\n",
    "Avoid overly general or vague terms, and do not hesitate to describe\n",
    "socially harmful or sensitive topics (in fact, clusters that clearly\n",
    "describe harmful behavior are slightly preferred); specificity is\n",
    "necessary for observability and enforcement.\n",
    "3. Ensure that the higher-level cluster names are distinct from one another.\n",
    "4. Use clear, concise, and descriptive language for the cluster names.\n",
    "Assume neither good nor bad faith for the content in the clusters.\n",
    "Now, provide your list of roughly {desired_names} higher-level cluster names.\n",
    "Present your answer in the following format:\n",
    "<answer>\n",
    "1. [First higher-level cluster name]\n",
    "2. [Second higher-level cluster name]\n",
    "3. [Third higher-level cluster name]\n",
    "...\n",
    "{desired_names}. [Last higher-level cluster name]\n",
    "</answer>\n",
    "Focus on creating meaningful, distinct, and precise (but not overly specific\n",
    ") higher-level cluster names that could encompass multiple sub-clusters.\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "assistant_prompt = \"\"\"I understand. I’ll evaluate the clusters and provide higher-level\n",
    "cluster names that could encompass multiple sub-clusters.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "chat_completion = client.chat.completions.create(\n",
    "     messages=[\n",
    "        {\"role\": \"developer\", \"content\": system_prompt},\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": user_prompt\n",
    "        },\n",
    "        {\"role\": \"assistant\", \"content\":assistant_prompt},\n",
    "\n",
    "    ],\n",
    "    model=\"gpt-3.5-turbo\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_names = chat_completion.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_text = re.sub(r'<answer>|</answer>', '', cluster_names)\n",
    "\n",
    "# Step 2: Extract the cluster names using a regex pattern\n",
    "pattern = r'\\d+\\.\\s*(.*)'  # Match the number and extract the cluster name\n",
    "\n",
    "# Find all matches\n",
    "cluster_list = re.findall(pattern, cleaned_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Agricultural Disease Research',\n",
       " 'Bee Health and Disease Studies',\n",
       " 'Plant and Pollination Research',\n",
       " 'Apiary Science Investigations',\n",
       " 'Integrated Agricultural Research',\n",
       " 'Bee Disease and Yield Studies',\n",
       " 'Pollinator Health Assessments',\n",
       " 'Agricultural Entomology Studies',\n",
       " 'Bee Ecology and Plant Health Research',\n",
       " 'Agricultural Research Initiatives',\n",
       " 'Bee and Plant Health Investigations',\n",
       " 'Field Biology Assessments',\n",
       " 'Bee Disease Experimentation',\n",
       " 'Agronomic Research on Bees and Plants',\n",
       " 'Entomological Survey and Analysis',\n",
       " 'Sustainable Agriculture Investigations',\n",
       " 'Pollen and Nectar Yield Studies',\n",
       " 'Bee Health Ecology Research',\n",
       " 'Agrarian Health and Disease Surveys',\n",
       " 'Bee Pollination Dynamics',\n",
       " 'Plant Pathology and Bee Health Research',\n",
       " 'Integrated Pest Management Studies',\n",
       " 'Agricultural Ecosystem Health Research',\n",
       " 'Pollinator Population Dynamics',\n",
       " 'Crop Yield Improvement Research',\n",
       " 'Bee Health and Disease Ecology',\n",
       " 'Environmental Impact Assessments',\n",
       " 'Sustainable Pollinator Management',\n",
       " 'Insect-Borne Disease Analysis',\n",
       " 'Pollinator Decline Investigations',\n",
       " 'Agricultural Sustainability Studies']"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster_list "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cluster_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deduplicate across neighborhoods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_prompt = f\"\"\"You are tasked with deduplicating a list of cluster names into a\n",
    "smaller set of distinct cluster names. Your goal is to create\n",
    "approximately {desired_names} relatively distinct clusters that best\n",
    "represent the original list. You are helping to organize user behavior\n",
    "data in order to improve safety, monitoring, and observability. Here are\n",
    "the inputs: \n",
    "{cluster_list}\n",
    "\n",
    "Number of distinct clusters to create: approximately {desired_names}\n",
    "Follow these steps to complete the task:\n",
    "1. Analyze the given list of cluster names to identify similarities,\n",
    "patterns, and themes.\n",
    "2. Group similar cluster names together based on their semantic meaning, not\n",
    "just lexical similarity.\n",
    "3. For each group, select a representative name that best captures the\n",
    "essence of the cluster. This can be one of the original names or a new\n",
    "name that summarizes the group effectively. Do not just pick the most\n",
    "vague or generic name.\n",
    "4. Merge the most similar groups until you reach the desired number of\n",
    "clusters. Maintain as much specificity as possible while merging.\n",
    "6. Ensure that the final set of cluster names are distinct from each other\n",
    "and collectively represent the diversity of the original list, such that\n",
    "there is a cluster that describes each of the provided clusters.\n",
    "7. If you create new names for any clusters, make sure they are clear,\n",
    "concise, and reflective of the contents they represent.\n",
    "42\n",
    "8. You do not need to come up with exactly {desired_names} names, but aim\n",
    "for no less than {int(desired_names * 0.5)} and no more than {int(\n",
    "desired_names * 1.5)}. Within this range, output as many clusters as you\n",
    "feel are necessary to accurately represent the variance in the original\n",
    "list. Avoid outputting duplicate or near-duplicate clusters.\n",
    "9. Do not hesitate to include clusters that describe socially harmful or\n",
    "sensitive topics (in fact, clusters that clearly describe harmful\n",
    "behavior are slightly preferred); specificity is necessary for effective\n",
    "monitoring and enforcement.\n",
    "10. Prefer outputting specific cluster names over generic or vague ones,\n",
    "provided the names are still correct; for example, if there are many\n",
    "clusters about a specific technology or tool, consider naming the\n",
    "cluster after that technology or tool, provided that there are still\n",
    "other clusters that fit under a broader category.\n",
    "The names you propose must follow these requirements:\n",
    "<criteria>(defined per facet)</criteria>\n",
    "Before providing your final answer, use the <scratchpad> tags to think\n",
    "through your process, explaining your reasoning for grouping and\n",
    "selecting representative names. Spend no more than a few paragraphs in\n",
    "your scratchpad.\n",
    "Present your final answer in the following format:\n",
    "\n",
    "<answer>\n",
    "1. [First cluster name]\n",
    "2. [Second cluster name]\n",
    "3. [Third cluster name]\n",
    "...\n",
    "N. [Nth cluster name]\n",
    "</answer>\n",
    "Remember, your goal is to create approximately {desired_names} relatively\n",
    "distinct cluster names that best represent the original list. The names\n",
    "should be clear, meaningful, and capture the essence of the clusters\n",
    "they represent.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "assistant_prompt =f\"\"\"I understand. I’ll deduplicate the cluster names into\n",
    "approximately {desired_names} names.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_completion = client.chat.completions.create(\n",
    "     messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": user_prompt\n",
    "        },\n",
    "        {\"role\": \"assistant\", \"content\":assistant_prompt},\n",
    "\n",
    "    ],\n",
    "    model=\"gpt-3.5-turbo\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"<scratchpad>\\nAfter analyzing the list of cluster names provided, I can see that there are several distinct themes present. These themes revolve around agricultural research, bee health, pollination studies, and environmental impact assessments. \\n\\nI will group together similar cluster names that fall under these themes and select representative names that capture the essence of each group. I will then merge the most similar groups while maintaining specificity to ensure the final set of cluster names is distinct and collectively represents the diversity of the original list. I will prioritize specific and clear names over generic ones to accurately describe the content of each cluster.\\n\\nI will start by identifying the key themes and then consolidate them into a smaller set of representative cluster names that best capture the original list's variance and diversity.\\n</scratchpad>\\n\\n<answer>\\n1. Agricultural Disease Research\\n2. Integrated Agricultural Research\\n3. Sustainable Agriculture Investigations\\n4. Agronomic Research on Bees and Plants\\n5. Crop Yield Improvement Research\\n6. Agricultural Sustainability Studies\\n7. Environmental Impact Assessments\\n8. Insect-Borne Disease Analysis\\n9. Pollinator Decline Investigations\\n10. Sustainable Pollinator Management\\n11. Plant and Pollination Research\\n12. Agrarian Health and Disease Surveys\\n13. Bee Pollination Dynamics\\n14. Pollinator Health Assessments\\n15. Entomological Survey and Analysis\\n16. Bee Disease Experimentation\\n17. Agronomic Research on Bees and Plants\\n18. Bee Health and Disease Ecology\\n19. Bee Ecology and Plant Health Research\\n20. Agricultural Ecosystem Health Research\\n21. Pollen and Nectar Yield Studies\\n22. Bee Health Ecology Research\\n23. Plant Pathology and Bee Health Research\\n24. Integrated Pest Management Studies\\n25. Pollinator Population Dynamics\\n26. Bee and Plant Health Investigations\\n27. Field Biology Assessments\\n28. Bee Disease and Yield Studies\\n29. Apiary Science Investigations\\n30. Bee Disease and Yield Studies\\n31. Bee Disease and Yield Studies\\n</answer>\""
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_completion.choices[0].message.content"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpt_eval",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
